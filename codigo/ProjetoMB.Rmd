---
title: "Modelação Bayesiana"
author: 
  - "Diogo Freitas"
  - "João Francisco Botas"
  - "Miguel Gonçalves"
  - "Ricardo Galvão"
date: "21-05-2025"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
#  html_document:
#    df_print: paged
#    code_folding: show
#    self_contained: true
#    keep_md: true

#  prettydoc::html_pretty:
#      theme: cayman
#      highlight: github
```


# Modelação Bayesiana

Este projeto foi desenvolvido no âmbito da unidade curricular de Modelação Bayesiana do Mestrado em Ciência de Dados no Iscte. O objetivo do trabalho tem como objetivo replicar um artigo científico do ponto de vista Bayesiana e discutir os resultados obtidos. Para além disso, vamos beneficiar das vantagens que a modelação Bayesiana nos traz, como por exemplo a possibilidade de fazer inferência causal e a utilização de priors informativas.

## Índice

- [Artigo de referência](#artigo-de-referência)

- [Fase 1 - EDA](#fase-1---eda)
  - [Variáveis categóricas](#variáveis-categóricas)
  - [Variáveis numéricas citadas no artigo](#variáveis-numéricas-citadas-no-artigo)
    - [Correlação entre variáveis](#correlação-entre-variáveis)
    - [Ver loadings e alpha de Cronbach](#ver-loadings-e-alpha-de-cronbach)
  - [Análise das variáveis](#análise-das-variáveis)
    - [Construtos criados no artigo](#construtos-criados-no-artigo)
    - [Variáveis não citadas no artigo](#variáveis-não-citadas-no-artigo)
    - [Variáveis descritivas](#variáveis-descritivas)
    - [Criar próprios CFA como fazem no artigo (erradamente)](#criar-próprios-cfa-como-fazem-no-artigo-erradamente)
  - [Criar ficheiros CSV na pasta data com os 4 conjuntos anteriores](#criar-ficheiros-csv-na-pasta-data-com-os-4-conjuntos-anteriores)

- [Fase 2 - Replicação do artigo](#fase-2---replicação-do-artigo)
  - [1 - CFA para cada conjunto de questões](#1---cfa-para-cada-conjunto-de-questões)
    - [CFA com todas as variáveis](#cfa-com-todas-as-variáveis)
    - [CFA com variáveis sugeridas pelo artigo](#cfa-com-variáveis-sugeridas-pelo-artigo)
    - [CFA com variáveis a escolher](#cfa-com-variáveis-a-escolher)
  - [2 - CFA Global](#2---cfa-global)
    - [Com as variáveis que os autores escolheram](#com-as-variáveis-que-os-autores-escolheram)
    - [Com as variáveis que escolhemos](#com-as-variáveis-que-escolhemos)
  - [3 - SEM](#3---sem)
    - [Estimação com construtos dos autores (dataset original)](#estimação-com-construtos-dos-autores-dataset-original)
    - [Construtos criados por nós](#construtos-criados-por-nós)
      - [Média variáveis](#média-variáveis)
      - [CFA](#cfa)
    - [Estimação com FA criadas no próprio modelo](#estimação-com-fa-criadas-no-próprio-modelo)
    - [Tentativa de melhoria com o SEM seguido](#tentativa-de-melhoria-com-o-sem-seguido)
    - [Comparação entre os dois SEM](#comparação-entre-os-dois-sem)

  - [4 - SEM com priors](#4---sem-com-priors)
    - [Priors para lambda, beta e ET12 e ET13](#priors-para-lambda-beta-e-et12-e-et13)
    - [Priors com regressão 0](#priors-com-regressão-0)
    - [Priors com todas priors](#priors-com-todas-priors)

## Artigo de referência

O artigo de referência para este trabalho é o [Data on higher education student ethics model](https://www.sciencedirect.com/science/article/pii/S2352340919312594?via%3Dihub). Este artigo analisa dados de um questionário aplicado a estudantes de ensino superior para avaliar a ética dos mesmos. O questionário foi aplicado a 566 estudantes entre o período de Janeiro a Dezembro de 2018, na cidade de Yogyakarta, na Indonesia. Para percebermos melhor o conjunto de dados e a sua estrutura, vamos carregar o ficheiro de dados e fazer uma pequena analise exploratória de dados, complementando a informação com a descrição do artigo.


```{r, include=FALSE}
# packages
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(foreign, haven, tidyverse, rstan, blavaan, lavaan, 
               brms, psych, bayesplot, skimr, semPlot, gridExtra, gridGraphics, 
               grid, corrplot, tictoc, fitdistrplus, knitr)

options(blavaan.dir = "temp_bcfa")
dir.create("temp_bcfa", showWarnings = FALSE)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

```{r}
# Escolher que modelos executar (sobretudo para a geração do ficheiro knited)

correr_single_CFAs_all <- FALSE
correr_single_CFAs_article <- FALSE
correr_single_CFAs_purpose <- correr_single_CFAs_article
correr_multiple_CFA <- FALSE
correr_SEM <- TRUE # TRUE
correr_SEM_cpriors <- TRUE # TRUE
```



## Fase 1 - EDA

```{r}
# load data
df <- read.csv("../data/dados_raw.csv")
# View(df)
# df %>% glimpse()
```

Skim do dataset para vermos a estrutura detalhada dos dados.

```{r, results='hold'}
df %>% skimr::skim() -> skim_output
###########
# skim_output
# str(skim_output) # ver a estrutura para filtrar
###########
min(skim_output$complete_rate) # todas as colunas têm valores preenchidos
max(colSums(is.na(df))) 
```

Ao guardarmos o skim num objeto podemos ver a estrutura e filtrar as informações que queremos. Neste caso, conseguimos ver que todas as colunas:
- têm todos os valores preenchidos $\rightarrow$ mínimo do `complete_rate` é 1;
- não existem valores em falta, consequentemente $\rightarrow$ máximo do número de valores em falta é 0.

Ou seja, não teremos de lidar com omissos.

```{r, results='hold'}
# select character columns
skim_output$skim_variable[skim_output$skim_type == "character"] -> char_cols
char_cols
# select numeric columns
skim_output$skim_variable[skim_output$skim_type == "numeric"] -> num_cols
length(num_cols) # = 127 total - 1 (Fak)
```

### Variáveis categóricas

No dataset só temos uma variável categórica, a `Fak`. Vamos fazer uma tabela de frequências para esta variável e um gráfico de barras. Esta variável, segundo o artigo, é a _faculty_/departamento a que o estudante pertence (**Table 8** artigo).

| Departamento                    | Nº alunos | Percentagem |
|---------------------------------|-----------|-------------|
| Economic                        |        114|        20.1%|
| Engineering                     |         98|        17.3%|
| Mathematics and Natural Science |         85|        15.0%|
| Social Science                  |         61|        10.8%|
| Sports Science                  |         15|         2.7%|
| Art                             |        120|        21.2%|
| Educational Science             |         73|        12.9%|
   

```{r}
# fazer uma tabela de frequências para as variáveis categóricas
df %>% dplyr::select(all_of(char_cols)) %>% map(table)
# gráfico de barras
df %>%
  group_by(Fak) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = reorder(Fak, -Percentage), y = Percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = paste0(round(Percentage, 1), "% (", Count, ")")), vjust = -0.5) +
  labs(x = "Field", y = "Percentage", title = "Distribution of Fields") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Conseguimos perceber que há uma relação com os resultados mencionados no artigo.


| Departamento                    | Sigla     |
|---------------------------------|-----------|
| Economic                        |         FE| 
| Engineering                     |         FT| 
| Mathematics and Natural Science |       MIPA| 
| Social Science                  |        FIS| 
| Sports Science                  |        FIK|
| Art                             |        FBS| 
| Educational Science             |        FIP| 


A partir de agora vamos guardar os dados num novo dataset para podermos fazer a modelação.

```{r}
df_transform <- df
df_transform <- df_transform %>%
  mutate(Fak = case_when(
    Fak == "FE" ~ "Economic",
    Fak == "FT" ~ "Engineering",
    Fak == "MIPA" ~ "Mathematics and Natural Science",
    Fak == "FIS" ~ "Social Science",
    Fak == "FIK" ~ "Sports Science",
    Fak == "FBS" ~ "Art",
    Fak == "FIP" ~ "Educational Science",
    TRUE ~ Fak
  ))
summary(as.factor(df_transform$Fak)) # factor para mostrar a coluna alterada
```

### Variáveis numéricas citadas no artigo

O artigo menciona que o questionário tem 7 grupos de perguntas que medem dimensões diferentes. Cada grupo está associado a um nome que, por sua vez, tem uma sigla associada.

1. **Ethical behaviour** (ET)
2. **Motivation** (Mot)
3. **Self-efficacy** (SE)
4. **Resilience** (R)
5. **Knowledge articulation** (KA)
6. **Team strain** (TS)
7. **Cooperative classroom environment** (CCE)

Vamos selecionar as variáveis que pertencem a cada grupo e guardá-las em objetos diferentes. No final vamos juntar estas variáveis num novo dataset.

```{r}
# select das variáveis numéricas mencionadas no artigo -> regex para ser + facil :)
ethical_behaviour <- df_transform %>%
  dplyr::select(matches("^ET[1-9]$|^ET1[0-4]$"))
#ethical_behaviour

motivation <- df_transform %>%
  dplyr::select(matches("^Mot[1-9]$|^Mot1[0-5]$"))
#motivation

self_efficacy <- df_transform %>%
  dplyr::select(matches("^SE[1-6]$"))
#self_efficacy

resilience <- df_transform %>%
  dplyr::select(matches("^R[1-6]$"))
#resilience

knowledge_articulation <- df_transform %>%
  dplyr::select(matches("^KA[1-5]$"))
#knowledge_articulation

team_strain <- df_transform %>%
  dplyr::select(matches("^TS[1-9]$|^TS1[0-7]$"))
#team_strain

cooperative_classroom_environment <- df_transform %>%
  dplyr::select(matches("^CCE[1-9]$|^CCE1[0-9]$|^CCE20$"))
#cooperative_classroom_environment

## falta 3xPOP; 6xPC; 6xOPT; 5xINO; 3xPDC

# juntar todos os dataframes com as colunas mencionadas no artigo (as acima)
vars_artigo <- bind_cols(ethical_behaviour, motivation, self_efficacy, 
                         resilience, knowledge_articulation, team_strain, 
                         cooperative_classroom_environment)
vars_artigo
```


**O que não consta no artigo: 3xPOP; 6xPC; 6xOPT; 5xINO; 3xPDC**

#### Correlação entre variáveis

```{r fig.width=12, fig.height=10}
construct_patterns <- list(
  ethical_behaviour = "^ET[1-9]$|^ET1[0-4]$",
  motivation = "^Mot[1-9]$|^Mot1[0-5]$",
  self_efficacy = "^SE[1-6]$",
  resilience = "^R[1-6]$",
  knowledge_articulation = "^KA[1-5]$",
  team_strain = "^TS[1-9]$|^TS1[0-7]$",
  cooperative_classroom_environment = "^CCE[1-9]$|^CCE1[0-9]$|^CCE20$"
)

for (name in names(construct_patterns)) {
  pattern <- construct_patterns[[name]]
  dataset <- df_transform %>% dplyr::select(matches(pattern))
  
  if (ncol(dataset) >= 2) {
    corr_matrix <- round(cor(dataset, use = "pairwise.complete.obs"), 2)
    
    corrplot(corr_matrix,
             method = "ellipse",
             type = "upper",  
             tl.col = "black",
             tl.cex = 0.8,
             addCoef.col = "black",
             number.cex = 1.0,
             mar = c(1, 1, 2, 1),
             title = paste("Matriz de Correlacao ", name))
  }
}
```

#### Ver loadings e alpha de Cronbach

Para cada grupo de variáveis, vamos calcular o alpha de Cronbach e os loadings. O alpha de Cronbach é uma medida de consistência interna, enquanto os loadings são as cargas fatoriais que indicam a relação entre as variáveis observadas e o fator latente a ser criado.

```{r}
calculate_metrics_all <- function(df, construct_patterns) {
  results <- list()
  
  for (name in names(construct_patterns)) {
    pattern <- construct_patterns[[name]]
    dataset <- df %>% dplyr::select(matches(pattern))
    
    if (ncol(dataset) >= 2) {
      alpha_result <- alpha(dataset)
      cronbach_alpha <- alpha_result$total$raw_alpha

      fa_result <- fa(dataset, nfactors = 1, rotate = "none")
      loadings <- fa_result$loadings[, 1]

      results[[name]] <- list(
        construct = name,
        cronbach_alpha = cronbach_alpha,
        loadings = loadings
      )
    }
  }

  for (metric in results) {
    cat("\nConstruct: ", metric$construct, "\n")
    cat("Cronbach Alpha: ", round(metric$cronbach_alpha, 2), "\n")
    cat("Factor Loadings:\n")
    print(round(metric$loadings, 2))
  }
  
  return(results)
}
```

Vamos primeiro experimentar com todas as variáveis dos itens que são citados no artigo. Após isso, experimentamos com aquelas que são mencionadas no artigo para fazer os construtos.

```{r}
metrics_results <- calculate_metrics_all(vars_artigo, construct_patterns)
```


```{r}
selected_construct_patterns <- list(
  ethical_behaviour = c("ET12", "ET13"),
  motivation = c("Mot5", "Mot8", "Mot11"),
  self_efficacy = c("SE1", "SE2", "SE3", "SE4", "SE5", "SE6"),
  resilience = c("R2", "R5", "R6"),
  knowledge_articulation = c("KA1", "KA2", "KA3", "KA4", "KA5"),
  team_strain = c("TS10", "TS11", "TS12", "TS13", "TS14", "TS15", "TS16", "TS17"),
  cooperative_classroom_environment = c("CCE1", "CCE3", "CCE4", "CCE5", "CCE8", "CCE9","CCE10", "CCE11")
)
metrics_results <- calculate_metrics_all(vars_artigo, selected_construct_patterns)
```


### Análise das variáveis


#### Construtos criados no artigo

Ainda, temos acesso aos construtos criados pelos autores do artigo após a fase de análise fatorial. Vamos selecionar estas variáveis e guardá-las num objeto. Os construtos estão referidos na **Table 9** do artigo.

```{r}
construtos_autores <- df_transform[, 121:127]
construtos_autores
```

#### Variáveis descritivas

Guardamos agora 8 variáveis do início do dataset que parecem ser apenas descritivas e que são referidas (algumas destas) no artigo, na tabela com as correlações. As correlações entre construtos pode ser encontrada na **Table 10** do artigo.

Uma destas variáveis é a `Fak` que já foi tratada anteriormente. Esta será incluída juntamente com as outras 7 e já terá os nomes alterados.

```{r}
descritivas <- df_transform[, 1:8]
descritivas
```


```{r}
skimr::skim(descritivas)$skim_variable
skimr::skim(descritivas)$numeric.p0
skimr::skim(descritivas)$numeric.p100
```


Após alguma pesquisa fomos tentar verificar o que representavam estas variáveis. 


- **Género**:Género da pessoa (pode ser 1 ou 2). À partida não sabemos qual corresponde ao feminino e ao masculino.
- **Tlahir**: Em indonésio pode ser uma abreviatura de Tanggal Lahir, que significa data de nascimento.
- **BLhair**: Em indonésio pode ser uma abreviatura de Bulan Lahir, que significa mês de nascimento.
- *Pengeluaran**: Em indonésio pode ser uma abreviatura de Pengeluaran, que significa despesas. Tradução direta para inglês $rightarrow$ Expenditure.


Verificamos o mínimo e o máximo de cada variável descritiva e percebemos alguns valores estranhos, dado o contexto pesquisado. Um deles é por exemplo o `Tlahir`. Talvez o valor mais alto $\rightarrow 31031999$ corresponde a $31/03/1999$. Para além disso o mês `BLhair` tem valores de 0 a 12, pelo que o 0 não faz muito sentido. 

```{r}
# ver todos os valores de Tlahir sorted descrescente
descritivas %>%
  dplyr::select(Tlahir) %>%
  dplyr::arrange(desc(Tlahir)) %>%
  dplyr::distinct() %>%
  dplyr::filter(Tlahir > 0) # ver os valores
```

- 31031999 $\rightarrow$ 1999			
- 16122000 $\rightarrow$ 2000					
- 11042000 $\rightarrow$ 2000					
- 302000 $\rightarrow$ 2000					
- 261998 $\rightarrow$ 1998					
- 241998 $\rightarrow$ 1998				
- 231997 $\rightarrow$ 1997				
- 221998 $\rightarrow$ 1998				
- 202000 $\rightarrow$ 2000				
- 200399 $\rightarrow$ 1999 (talvez é 20/03/99)
- 81999 $\rightarrow$ 1999				
- 71999 $\rightarrow$ 1999				
- 20000 $\rightarrow$ 2000				
- 3200 $\rightarrow$ 2000 (talvez é 3/2/00)

```{r}
descritivas <- descritivas %>%
  mutate(Tlahir = case_when(
    Tlahir == 31031999 ~ 1999,
    Tlahir == 16122000 ~ 2000,
    Tlahir == 11042000 ~ 2000,
    Tlahir == 302000   ~ 2000,
    Tlahir == 261998   ~ 1998,
    Tlahir == 241998   ~ 1998,
    Tlahir == 231997   ~ 1997,
    Tlahir == 221998   ~ 1998,
    Tlahir == 202000   ~ 2000,
    Tlahir == 200399   ~ 1999,
    Tlahir == 81999    ~ 1999,
    Tlahir == 71999    ~ 1999,
    Tlahir == 20000    ~ 2000,
    Tlahir == 3200     ~ 2000,
    TRUE ~ as.numeric(Tlahir)  # mantém outros valores como estão
  ))
```

```{r}
descritivas %>%
  group_by(Tlahir) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = Count / sum(Count) * 100) %>%
  ggplot(aes(x = factor(Tlahir), y = Percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = paste0(round(Percentage, 1), "% (", Count, ")")), vjust = -0.5) +
  labs(x = "Ano de Nascimento (Tlahir)", y = "Porcentagem", title = "Distribuição por Ano de Nascimento dos 566 inquiridos") +
  theme_minimal()
```


```{r, fig.width=9, fig.height=6}
df_percent <- df %>%
  group_by(Gender, IPK) %>%
  summarise(Count = n(), .groups = "drop") %>%
  mutate(Percentage = round(Count / sum(Count) * 100, 1))


ggplot(descritivas, aes(x = as.factor(Gender), y = IPK, color = Pengeluaran)) +
  geom_jitter(width = 0.4, height = 0.23, alpha = 0.67, size = 2.0) +
  geom_text(data = df_percent, aes(x = as.factor(Gender), y = as.numeric(IPK) + 0.2,
                                   label = paste0(Percentage, "%")),
            color = "black", size = 3.2, vjust = -1.2, inherit.aes = FALSE) +
  geom_vline(xintercept = 1.5, linetype = "dashed", color = "grey85", linewidth = 0.3) +
  scale_color_gradientn(colors = c("#3CBA96", "#78C461", "#FFD666", "#DD8D4A" ,"#EC5353"), name = "Pengeluaran") +
  scale_x_discrete(limits = c("1", "2"), labels = c("1" = "1", "2" = "2")) +
  labs(
    x = "Sexo do inquirido (sem informação da etiqueta M/F)",
    y = "IPK (GPA)",
    title = "Distribuição de IPK (GPA) por Sexo",
    subtitle = "Cores representa as despesas (Pengeluaran: 1 a 5)"
  ) +
  theme_minimal() +
  theme(
  plot.title = element_text(hjust = 0.5, face = "bold", size = 16), 
  plot.subtitle = element_text(hjust = 0.5),                        
  legend.title = element_text(face = "bold"),
  legend.title.align = 0.5,           
  legend.text = element_text(face = "bold"),
  legend.key.width = unit(1.5, "lines"),
  legend.spacing.x = unit(0.3, "cm"),
  axis.title.x = element_text(face = "bold"),
  axis.title.y = element_text(face = "bold"),
  axis.text.x = element_text(angle = 0, hjust = 0.5)
)

# ggsave("ipk_genero_plot.png", width = 9, height = 6, dpi = 300)
```

```{r}
df_gender <- descritivas %>%
  count(Gender) %>%
  mutate(
    Percentage = round(n / sum(n) * 100, 2),
    Label = paste0(Percentage, "% (", n, ")")
  )

ggplot(df_gender, aes(x = "", y = n, fill = as.factor(Gender))) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar(theta = "y") +
  geom_text(aes(label = Label), position = position_stack(vjust = 0.5), color = "white", size = 4.5) +
  scale_fill_manual(
    values = c("1" = "blue",  # Roxo
               "2" = "darkgreen"), # Amarelo
    name = "Sexo",
    labels = c("1" = "1", "2" = "2")
  ) +
  labs(title = "Distribuição de Sexo") +
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```


#### Variáveis não citadas no artigo

As colunas que não estão nos outros datasets.

```{r}
# selecionar do dataset df_transform aquelas que não estao em descritivas, vars_artigo e construtos_autores
vars_nao_citadas <- df_transform %>%
  dplyr::select(-all_of(c(colnames(descritivas), colnames(vars_artigo), colnames(construtos_autores))))
vars_nao_citadas
```

Estas colunas, assim como as variáveis descritivas, vamos ignorar porque não servem para a replicação do artigo.

#### Criar próprios CFA como fazem no artigo (erradamente)

Vamos começar por fazer uma análise fatorial confirmatória (CFA) com as variáveis que foram criados pelos autores do artigo. Vamos usar a função `cfa` do pacote `lavaan`.

```{r, echo=TRUE, results='hide'}
run_CFA_extract_scores <- function(df, construtos_lista) {
  df_resultado <- data.frame(matrix(nrow = nrow(df), ncol = 0))
  modelos <- list()
  
  for (nome_construto in names(construtos_lista)) {
    itens <- construtos_lista[[nome_construto]]
    formula_cfa <- paste0(nome_construto, " =~ ", paste(itens, collapse = " + "))
    
    modelo <- cfa(formula_cfa, data = df, std.lv = TRUE)
    modelos[[nome_construto]] <- modelo 
    
    cat("\n\n--- CFA:", nome_construto, "---\n")
    print(summary(modelo, standardized = TRUE, rsquare = TRUE))
    
    loadings <- parameterEstimates(modelo) %>% filter(op == "=~")
    print(loadings)
    
    # CFA scores
    scores <- lavPredict(modelo)
    if (is.vector(scores)) {
      df_resultado[[paste0("score_", nome_construto)]] <- scores
    } else if (is.matrix(scores)) {
      df_resultado[[paste0("score_", nome_construto)]] <- scores[, 1]
    }
  }
  
  return(list(scores_df = df_resultado, modelos = modelos))
}

construtos <- list(
  factor_Ethics = c("ET12", "ET13"),
  factor_Motivation = c("Mot5", "Mot8", "Mot11"),
  factor_SelfEfficacy = c("SE1", "SE2", "SE3", "SE4", "SE5", "SE6"),
  factor_Resilience = c("R2", "R5", "R6"),
  factor_KnowledgeArticulation = c("KA1", "KA2", "KA3", "KA4", "KA5"),
  factor_TeamStrain = c("TS10", "TS11", "TS12", "TS13", "TS14", "TS15", "TS16", "TS17"),
  factor_CooperativeClassroomEnvironment = c("CCE1", "CCE3", "CCE4", "CCE5", "CCE8", "CCE9", "CCE10", "CCE11")
)

resultado_CFA <- run_CFA_extract_scores(df, construtos)
df_OUR_CFA <- resultado_CFA$scores_df

# modelos_CFA <- resultado_CFA$modelos
```

Para além do CFA, vamos ver como seria se fizéssemos a média, pois os autores também o fazem para ter os construtos "Motivation", "SelfEfficacy", "Resilience", etc.. Apenas nos apercebemos disto porque o dataset contém a informação dos construtos que os autores criaram e podemos perceber que não representavam scores, apenas uma média das variáveis. Por exemplo: Student Ethics: (ET12+ET13)/2 para cada uma das 566 linhas/respostas.

```{r, echo=TRUE, results='hide'}
run_item_means <- function(df, construtos_lista) {
  df_resultado <- data.frame(matrix(nrow = nrow(df), ncol = 0))
  
  for (nome_construto in names(construtos_lista)) {
    itens <- construtos_lista[[nome_construto]]
    
    media_itens <- rowMeans(df[, itens], na.rm = TRUE)
    df_resultado[[paste0("mean_", nome_construto)]] <- media_itens
  }
  return(df_resultado)
}

construtos <- list(
  factor_Ethics = c("ET12", "ET13"),
  factor_Motivation = c("Mot5", "Mot8", "Mot11"),
  factor_SelfEfficacy = c("SE1", "SE2", "SE3", "SE4", "SE5", "SE6"),
  factor_Resilience = c("R2", "R5", "R6"),
  factor_KnowledgeArticulation = c("KA1", "KA2", "KA3", "KA4", "KA5"),
  factor_TeamStrain = c("TS10", "TS11", "TS12", "TS13", "TS14", "TS15", "TS16", "TS17"),
  factor_CooperativeClassroomEnvironment = c("CCE1", "CCE3", "CCE4", "CCE5", "CCE8", "CCE9", "CCE10", "CCE11")
)

df_means_only <- run_item_means(df, construtos)
```

Juntar os dois datasets para serem utilizados depois.

```{r}
# juntar os dois dataframes
df_OUR_results <- cbind(df_OUR_CFA, df_means_only)
colnames(df_OUR_results)
df_OUR_results
```


### Criar ficheiros csv na pasta data com os 4 conjuntos anteriores

Guardar numa pasta específica para ajudar os dados mais facilmente com a separação realizada. Isto porque algumas variáveis serão utilizadas e outras não.

```{r}
# escrever uma função
write_csvs <- function(data, name){
  write_csv(data, paste0("../data/4_conjuntos(dev)/", name, ".csv"))
}
write_csvs(descritivas, "descritivas")
write_csvs(vars_artigo, "vars_artigo")
write_csvs(construtos_autores, "construtos_autores")
write_csvs(vars_nao_citadas, "vars_nao_citadas")
write_csvs(df_OUR_results, "df_OUR_results")
```


## Fase 2: Replicação do artigo

Depois de percebermos o dataset que temos e o que é que os autores fizeram, vamos replicar o artigo. Vamos fazer a replicação do artigo de forma a percebermos como é que os autores chegaram aos resultados e discutir os valores obtidos do ponto de vista de Bayesiana.

### 1 - CFA para cada conjunto de questões

```{r}
# ler csv 
df <- read.csv("../data/4_conjuntos(dev)/vars_artigo.csv")
df
```

Como primeira análise vamos fazer uma análise fatorial confirmatória (CFA) para tentar verificar se as variáveis utilizadas nos construtos são as que têm valores de loadings mais elevados. Vamos usar o pacote `blavaan` para fazer a modelação bayesiana.

```{r}
# individual params
n_chains <- 3 # 5
burn_in <- 1500
sample_estimate <- 3000
```

A função `bcfa` do pacote `blavaan` é utilizada para fazer a modelação bayesiana. Esta função tem como parâmetros o modelo, os dados, o número de cadeias, o burn-in e o número de amostras.

Vamos fazer o semplot para ver os resultados da modelação. O semPaths é uma função do pacote `semPlot` que permite visualizar os resultados da modelação.

```{r}
plot_sem_model <- function(model, title = "") {
  semPaths(model,
           what = "std",
           layout = "spring",
           edge.label.cex = 0.6,
           sizeMan = 3,
           sizeLat = 7,
           nCharNodes = 4,
           residuals = TRUE,
           intercepts = FALSE,
           optimizeLatRes = TRUE,
           edge.color = "darkgreen",
           color = list(lat = "skyblue", man = "white"),
           node.width = 2,
           mar = c(6, 6, 6, 6))
}
```

Já fizemos uma análise fatorial confirmatória (CFA) para tentar verificar se as variáveis utilizadas nos construtos são as que têm valores de loadings mais elevados. Vamos usar o pacote `blavaan` para fazer a modelação bayesiana de cada grupo de variáveis em separado. 

Para isso vamos seguir três abordagens:

- A primeira abordagem com todas as variáveis para cada construto a ser constituído;
- A segunda abordagem será com as variáveis consideradas no artigo para a formação dos construtos;
- A terceira abordagem com as variáveis que têm os loadings mais elevados para cada construto a ser constituído.


#### CFA com todas as variáveis para tentar justificar/perceber as escolhas para os construtos

Esta é a primeira abordagem em que vamos verificar os valores dos loadings e tentar justificar as escolhas dos autores.

**Nota**: é necessário ter em conta que os autores não utilizaram todas as variáveis para a formação dos construtos e podem ter optado por algumas pelos valores dos loadings ou pelas perguntas que fariam mais sentido dado o questionário. Levaremos isso em conta.

##### Student Ethics

```{r stethics todas}
if(correr_single_CFAs_all){
  # Student Ethics
  model.ethics <- 'StudentEthics =~ ET1 + ET2 + ET3 + ET4 + ET5 + ET6 + ET7 + 
                                    ET8 + ET9 + ET10 + ET11 + ET12 + ET13 + ET14'
  fit.ethics <- bcfa(model.ethics, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.ethics, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.ethics)
}
```

1500 burn-in + 3000 samples

| Item  | Loadings  |
|-------|-----------|
| ET1   | 0.183     |
| ET2   | 0.244     |
| ET3   | 0.258     |
| ET4   | 0.221     |
| ET5   | 0.275     |
| ET6   | 0.288     |
| ET7   | 0.198     |
| ET8   | 0.194     |
| ET9   | 0.190     |
| ET10  | 0.395     |
| ET11  | 0.411     |
| ET12  | **0.741**     |
| ET13  | **0.749**     |
| ET14  | 0.364     |

O artigo opta por selecionar apenas 2 variáveis para o `Student Ethics` (ET12 e ET13), que são os que têm os loadings mais expressivos! Por isso, acabamos por concordar e não vamos incluir ou excluir variáveis.

##### Motivation

```{r motivation todas}
if(correr_single_CFAs_all){
  # Motivation
  model.motivation <- 'Motivation =~ Mot1 + Mot2 + Mot3 + Mot4 + Mot5 + 
                                    Mot6 + Mot7 + Mot8 + Mot9 + Mot10 + 
                                    Mot11 + Mot12 + Mot13 + Mot14 + 
                                    Mot15'
  fit.motivation <- bcfa(model.motivation, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.motivation, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.motivation)
}
```

1500 burn-in + 3000 samples

| Item  | Loadings  |
|--------|----------|
| Mot1   | 0.364    |
| Mot2   | 0.386    |
| Mot3   | 0.244    |
| Mot4   | 0.368    |
| Mot5   | -0.078   |
| Mot6   | 0.409    |
| Mot7   | 0.259    |
| Mot8   | -0.101   |
| Mot9   | 0.354    |
| Mot10  | 0.318    |
| Mot11  | -0.058   |
| Mot12  | 0.285    |
| Mot13  | 0.422    |
| Mot14  | 0.354    |
| Mot15  | -0.165   |

O artigo opta por selecionar apenas 3 variáveis para o `Motivation` (Mot5, Mot8 e Mot11), que são os que têm os loadings negativos, a par do Mot15. São as três variáveis que têm os loadings mais parto de 0 (com diferença menor que 0.1), que talvez seja uma forma de tentar perceber a relação entre a pouca motivação e a ética.
 
##### Self-Efficacy

```{r selfeff todas}
if(correr_single_CFAs_all){
  # Self-Efficacy
  model.efficacy <- 'SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6'
  fit.efficacy <- bcfa(model.efficacy, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.efficacy, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.efficacy)
}
```

1500 burn-in + 3000 samples

| Item  | Loadings  |
|-------|-----------|
| SE1   | 0.414     |
| SE2   | 0.447     |
| SE3   | 0.514     |
| SE4   | 0.494     |
| SE5   | 0.441     |
| SE6   | 0.458     |

Optam-se por utilizar todas as variáveis para o `Self Efficacy`, dado que todas têm loadings positivos e acima de 0.4.

##### Resilience

```{r res todas}
if(correr_single_CFAs_all){
  # Resilience
  model.resilience <- 'Resilience =~ R1 + R2 + R3 + R4 + R5 + R6'
  fit.resilience <- bcfa(model.resilience, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.resilience, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.resilience)
}
```

1500 burn-in + 3000 samples

| Item  | Loadings  |
|-------|-----------|
| R1    | 0.438     |
| R2    | 0.501     |
| R3    | 0.356     |
| R4    | 0.381     |
| R5    | 0.548     |
| R6    | 0.485     |

O artigo opta por selecionar 3 variáveis para o `Resilience` (R2, R5 e R6), que são os que têm os loadings mais expressivos (os três arredondados são acima 0.5).


##### Knowledge Articulation

```{r ka todas}
if(correr_single_CFAs_all){
  # Knowledge Articulation
  model.knowledge <- 'KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5'
  fit.knowledge <- bcfa(model.knowledge, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.knowledge, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.knowledge)
}
```

1500 burn-in + 3000 samples

| Item  | Loadings  |
|-------|-----------|
| KA1   | 0.476     |
| KA2   | 0.521     |
| KA3   | 0.476     |
| KA4   | 0.510     |
| KA5   | 0.449     |

O artigo opta por selecionar todas as variáveis para o `Knowledge Articulation`, dado que todas têm loadings positivos e acima de 0.4.


##### Team Strain

```{r ts todas}
if(correr_single_CFAs_all){
  # Team Strain
  model.teamstrain <- 'TeamStrain =~ TS1 + TS2 + TS3 + TS4 + TS5 + 
                                    TS6 + TS7 + TS8 + TS9 + TS10 + 
                                    TS11 + TS12 + TS13 + TS14 + 
                                    TS15 + TS16 + TS17'
  fit.teamstrain <- bcfa(model.teamstrain, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.teamstrain, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.teamstrain)
}
```

1500 burn-in + 3000 samples

| Item  | Loadings  |
|-------|-----------|
| TS1    | 0.295     |
| TS2    | 0.216     |
| TS3    | 0.266     |
| TS4    | 0.245     |
| TS5    | 0.284     |
| TS6    | 0.288     |
| TS7    | 0.350     |
| TS8    | 0.355     |
| TS9    | 0.415     |
| TS10   | 0.485     |
| TS11   | 0.491     |
| TS12   | 0.503     |
| TS13   | 0.500     |
| TS14   | 0.506     |
| TS15   | 0.549     |
| TS16   | 0.455     |
| TS17   | 0.450     |

O artigo opta por selecionar 8 variáveis para o `Team Strain` (TS10, TS11, TS12, TS13, TS14, TS15, TS16 e TS17), que são os que têm os loadings mais expressivos (os 8 arredondados são acima 0.5).


##### Cooperative Classroom Environment

```{r cce todas}
if(correr_single_CFAs_all){
  # Cooperative Classroom Environment
  model.cce <- 'CooperativeClassroomEnvironment =~ CCE1 + CCE2 + CCE3 + 
                                    CCE4 + CCE5 + CCE6 + CCE7 + CCE8 + 
                                    CCE9 + CCE10 + CCE11 + CCE12 + CCE13 +
                                    CCE14 + CCE15 + CCE16 + CCE17 + CCE18 +
                                    CCE19 + CCE20'
  fit.cce <- bcfa(model.cce, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.cce, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.cce)
}
```

1500 burn-in + 3000 samples

| Item  | Loadings  |
|-------|-----------|
| CCE1   | 0.466     |
| CCE2   | 0.145     |
| CCE3   | 0.357     |
| CCE4   | 0.321     |
| CCE5   | 0.418     |
| CCE6   | 0.325     |
| CCE7   | 0.388     |
| CCE8   | 0.389     |
| CCE9   | 0.413     |
| CCE10  | 0.418     |
| CCE11  | 0.415     |
| CCE12  | 0.330     |
| CCE13  | 0.413     |
| CCE14  | 0.412     |
| CCE15  | 0.278     |
| CCE16  | 0.472     |
| CCE17  | 0.445     |
| CCE18  | 0.466     |
| CCE19  | 0.455     |
| CCE20  | 0.396     |

O artigo opta por selecionar 8 variáveis para o `Cooperative Classroom Environment` (CCE1, CCE3, CCE4, CCE5, CCE8, CCE9, CCE10 e CCE11). 


##### Gráficos 

Desenhar os semplots com a função definida acima.

```{r graficos todas}
if(correr_single_CFAs_all){
  p1 <- plot_sem_model(fit.ethics, "Student Ethics")
  p2 <- plot_sem_model(fit.motivation, "Motivation")
  p3 <- plot_sem_model(fit.efficacy, "Self Efficacy")
  p4 <- plot_sem_model(fit.resilience, "Resilience")
  p5 <- plot_sem_model(fit.knowledge, "Knowledge Articulation")
  p6 <- plot_sem_model(fit.teamstrain, "Team Strain")
  p7 <- plot_sem_model(fit.cce, "Cooperative Classroom Environment")
}
```

Distribuição de N(0,10) para lambda e Gama(1,0.5) para a variância.

```{r}
plot(seq(0,10,.1), dnorm(seq(0,10,.1),0,10), type="l", lty=1, lwd = 3, xlab="x value",
     ylab="Density", main="Prior Latent variables: normal distribution (0,10)")
# vertical line
abline(v=1, col="darkred", lwd=2)
abline(v=5, col="darkred", lwd=2)
```

```{r}
plot(seq(0,10,.1), dgamma(seq(0,10,.1),1,0.5), type="l", lty=1, lwd = 3, xlab="x value",
     ylab="Density", main="Prior Var: gamma distribution (1,0.5)")
```

#### CFA com as variáveis sugeridos pelo artigo

Agora vamos restringir ao conjunto de variáveis que os autores escolheram para cada construto. Usamos o pacote `blavaan` para fazer a modelação bayesiana.

```{r}
# individual params
n_chains <- 3 # 5
burn_in <- 1500
sample_estimate <- 3000
```

##### Student Ethics

```{r stethics artigo}
if(correr_single_CFAs_article){
  # Student Ethics
  model.ethics_article <- 'StudentEthics =~ ET12 + ET13'
  fit.ethics_article <- bcfa(model.ethics_article, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.ethics_article, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.ethics_article)
}
```

São apenas 2 variáveis e parecem adequadas para usarmos só estas.

##### Motivation

```{r motivation artigo}
if(correr_single_CFAs_article){
  # Motivation
  model.motivation_article <- 'Motivation =~ Mot5 + Mot8 + Mot11'
  fit.motivation_article <- bcfa(model.motivation_article, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.motivation_article, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.motivation_article)
}
```

Eram as únicas que tinham os loadings negativos quando fizemos para todas as variáveis (também as únicas utilizadas pelos autores), mas parecem ser adequadas para usarmos só estas. Valores de loadings altos e 

##### Self-Efficacy

```{r selfeff artigo}
if(correr_single_CFAs_article){
  # Self-Efficacy
  model.efficacy_article <- 'SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6'
  fit.efficacy_article <- bcfa(model.efficacy_article, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.efficacy_article, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.efficacy_article)
}
```

São utilizadas todos os itens para o construto, deixaremos assim mesmo.

##### Resilience

```{r res artigo}
if(correr_single_CFAs_article){
  # Resilience
  model.resilience_article <- 'Resilience =~ R2 + R5 + R6'
  fit.resilience_article <- bcfa(model.resilience_article, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.resilience_article, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.resilience_article)
}
```

São utilizadas 3 variáveis para o construto, que são as que têm os loadings mais expressivos quando usadas todos os itens. O R2 parece que tem o loading mais baixo e, por isso, testaremos com R5 e R6 apenas para critério de comparação.

##### Knowledge Articulation

```{r ka artigo}
if(correr_single_CFAs_article){
  # Knowledge Articulation
  model.knowledge_article <- 'KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5'
  fit.knowledge_article <- bcfa(model.knowledge_article, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.knowledge_article, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.knowledge_article)
}
```

São utilizadas todos os itens para o construto, deixaremos assim mesmo.

##### Team Strain

```{r ts artigo}
if(correr_single_CFAs_article){
  # Team Strain
  model.teamstrain_article <- 'TeamStrain =~ TS10 + TS11 + TS12 + TS13 + 
                                     TS14 + TS15 + TS16 + TS17'
  fit.teamstrain_article <- bcfa(model.teamstrain_article, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.teamstrain_article, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.teamstrain_article)
}
```

São utilizados aqueles que têm os loadings mais expressivos e são os que os autores escolheram. Os valores continuam altos e por isso deixamos.

##### Cooperative Classroom Environment

```{r cce artigo}
if(correr_single_CFAs_article){
  # Cooperative Classroom Environment
  model.cce_article <- 'CooperativeClassroomEnvironment =~ CCE1 + CCE3 + CCE4 + 
                                    CCE5 + CCE8 + CCE9 + CCE10 + CCE11'
  fit.cce_article <- bcfa(model.cce_article, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.cce_article, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.cce_article)
}
```

Este construto parece ter itens mais interessantes para serem testados, então vamos experimentar com os valores mais altos e ver mais detalhadamente para tentar melhorar a análise.

- CCE1: 0.488
- CCE3: 0.421
- CCE4: 0.406
- CCE5: 0.435
- CCE8: 0.422
- CCE9: 0.506
- CCE10: 0.482
- CCE11: 0.499


##### Gráficos 


```{r graficos artigo}
if(correr_single_CFAs_article){
  p1 <- plot_sem_model(fit.ethics_article, "Student Ethics")
  p2 <- plot_sem_model(fit.motivation_article, "Motivation")
  p3 <- plot_sem_model(fit.efficacy_article, "Self Efficacy")
  p4 <- plot_sem_model(fit.resilience_article, "Resilience")
  p5 <- plot_sem_model(fit.knowledge_article, "Knowledge Articulation")
  p6 <- plot_sem_model(fit.teamstrain_article, "Team Strain")
  p7 <- plot_sem_model(fit.cce_article, "Cooperative Classroom Environment")
}
```

#### CFA com variáveis a escolher

Vamos apenas alterar os construtos de "Resilience" e o de "Cooperative Classroom Environment" para ver se conseguimos melhorar os resultados. Serão ajustados os valores e, após isso, comparados com o CFA já realizado.

```{r}
construct_patterns <- list(
  resilience = "^R[1-6]$",
  cooperative_classroom_environment = "^CCE[1-9]$|^CCE1[0-9]$|^CCE20$"
)

selected_construct_patterns <- list(
  resilience_com_R2 = c("R2", "R5", "R6"),
  resilience_sem_R2 = c("R5", "R6"), # retirar o R2 apesar de ter um valor alto
  cce = c("CCE1", "CCE5", "CCE10", "CCE11", "CCE16", "CCE17", "CCE18", "CCE19") 
)

# metrics_results_search1 <- calculate_metrics_all(vars_artigo, construct_patterns)
# metrics_results_search2 <- calculate_metrics_all(vars_artigo, selected_construct_patterns)
```

Para o Resilience vimos que se retirarmos os valores dos loadings ficam melhores e, ao mesmo tempo, o alpha de Cronbach também melhora. Contudo, ficaríamos só com 2 variáveis, o que não é muito interessante porque não tem graus de liberdade (df=0). Vamos testar, mas teremos isto em consideração.

##### Resilience

```{r res proposta}
if(correr_single_CFAs_purpose){
  # Resilience
  model.resilience_purpose <- 'Resilience =~ R5 + R6'
  fit.resilience_purpose <- bcfa(model.resilience_purpose, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.resilience_purpose, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.resilience_purpose)
}
```

```{r compres proposta}
if(correr_single_CFAs_purpose){
  blavCompare(fit.resilience_article, fit.resilience_purpose)
}
```

O modelo sem R2 e só com 2 variáveis parece ser melhor.

##### Cooperative Classroom Environment

```{r cce proposta}
if(correr_single_CFAs_purpose){
  # Cooperative Classroom Environment
  model.cce_purpose <- 'CooperativeClassroomEnvironment =~ CCE1 + CCE5 + CCE10 + CCE11 + 
                                                           CCE16 + CCE17  + CCE18 + CCE19'
  fit.cce_purpose <- bcfa(model.cce_purpose, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
  summary(fit.cce_purpose, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fit.cce_purpose)
}
```

```{r compcce proposta}
if(correr_single_CFAs_purpose){
  blavCompare(fit.cce_article, fit.cce_purpose)
}
```

O modelo com as variáveis escolhidas parece ser melhor, mas não temos certeza se é mesmo assim e se os itens foram escolhidos pelo seu significado. Isto apenas porque não temos detalhes o que todos os itens indicam, só do CCE1 até ao CCE5.

Vamos sempre comparar as duas abordagens e ver se as nossas variáveis propostas acabam por ser melhores.

### 2 - CFA Global

Vai ter em conta as covariâncias entre os fatores e ver as variâncias.

```{r}
# individual params
n_chains <- 3 # 5
burn_in <- 500
sample_estimate <- 1500
```


#### Com as variáveis que os autores escolheram

```{r multipleCFA article}
if(correr_multiple_CFA){
  modelcfa.authors <- '
    StudentEthics =~ ET12 + ET13
    Motivation =~ Mot5 + Mot8 + Mot11
    SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
    Resilience =~ R2 + R5 + R6
    KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
    TeamStrain =~ TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
    CooperativeClassroomEnvironment =~ CCE1 + CCE3 + CCE4 + CCE5 + CCE8 + CCE9 + CCE10 + CCE11
    
     # variances
    ET12 ~~ ET12
    ET13 ~~ ET13
    Mot5 ~~ Mot5
    Mot8 ~~ Mot8
    Mot11 ~~ Mot11
    SE1 ~~ SE1
    SE2 ~~ SE2
    SE3 ~~ SE3
    SE4 ~~ SE4
    SE5 ~~ SE5
    SE6 ~~ SE6
    R2 ~~ R2
    R5 ~~ R5
    R6 ~~ R6
    KA1 ~~ KA1
    KA2 ~~ KA2
    KA3 ~~ KA3
    KA4 ~~ KA4
    KA5 ~~ KA5
    TS10 ~~ TS10
    TS11 ~~ TS11
    TS12 ~~ TS12
    TS13 ~~ TS13
    TS14 ~~ TS14
    TS15 ~~ TS15
    TS16 ~~ TS16
    TS17 ~~ TS17
    CCE1 ~~ CCE1
    CCE3 ~~ CCE3
    CCE4 ~~ CCE4
    CCE5 ~~ CCE5
    CCE8 ~~ CCE8
    CCE9 ~~ CCE9
    CCE10 ~~ CCE10
    CCE11 ~~ CCE11
  '
  fitcfa.authors <- bcfa(modelcfa.authors, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
}
```


```{r}
if(correr_multiple_CFA){
  summary(fitcfa.authors, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fitcfa.authors)
}
```

```{r}
if(correr_multiple_CFA){
  semPaths(fitcfa.authors,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 6,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "white"),
           mar = c(6, 6, 6, 6) 
  )
}
```

#### Com as variáveis que escolhemos

```{r multipleCFA nossa escolha}
if(correr_multiple_CFA){
  modelcfa.purpose <- '
    StudentEthics =~ ET12 + ET13
    Motivation =~ Mot5 + Mot8 + Mot11
    SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
    Resilience =~ R5 + R6
    KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
    TeamStrain =~ TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
    CooperativeClassroomEnvironment =~ CCE1 + CCE5 + CCE10 + CCE11 + CCE16 + CCE17 + CCE18 + CCE19
    
     # variances
    ET12 ~~ ET12
    ET13 ~~ ET13
    Mot5 ~~ Mot5
    Mot8 ~~ Mot8
    Mot11 ~~ Mot11
    SE1 ~~ SE1
    SE2 ~~ SE2
    SE3 ~~ SE3
    SE4 ~~ SE4
    SE5 ~~ SE5
    SE6 ~~ SE6
    # R2 ~~ R2
    R5 ~~ R5
    R6 ~~ R6
    KA1 ~~ KA1
    KA2 ~~ KA2
    KA3 ~~ KA3
    KA4 ~~ KA4
    KA5 ~~ KA5
    TS10 ~~ TS10
    TS11 ~~ TS11
    TS12 ~~ TS12
    TS13 ~~ TS13
    TS14 ~~ TS14
    TS15 ~~ TS15
    TS16 ~~ TS16
    TS17 ~~ TS17
    CCE1 ~~ CCE1
    CCE5 ~~ CCE5
    CCE10 ~~ CCE10
    CCE11 ~~ CCE11
    CCE16 ~~ CCE16
    CCE17 ~~ CCE17
    CCE18 ~~ CCE18
    CCE19 ~~ CCE19
  '
  fitcfa.purpose <- bcfa(modelcfa.purpose, data = df, std.lv = TRUE,
                        n.chains = n_chains, burnin=burn_in, 
                        sample=sample_estimate, target = "stan")
}
```

```{r}
if(correr_multiple_CFA){
  summary(fitcfa.purpose, standardized = TRUE, rsquare = TRUE)
  fitMeasures(fitcfa.purpose)
}
```

```{r}
if(correr_multiple_CFA){
  semPaths(fitcfa.purpose,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 6,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "white"),
           mar = c(6, 6, 6, 6) 
  )
}
```

#### (X) Com todas as variáveis

Demora muito tempo a correr.

```{r}
if(FALSE){
modelcfa.global <- '
  StudentEthics =~ ET1 + ET2 + ET3 + ET4 + ET5 + ET6 + ET7 + ET8 + ET9 + ET10 + ET11 + ET12 + ET13
  Motivation =~ Mot1 + Mot2 + Mot3 + Mot4 + Mot5 + Mot6 + Mot7 + Mot8 + Mot9 + Mot10 + Mot11 + Mot12 + Mot13 + Mot14 + Mot15
  SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
  Resilience =~ R1 + R2 + R3 + R4 + R5 + R6
  KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
  TeamStrain =~ TS1 + TS2 + TS3 + TS4 + TS5 + TS6 + TS7 + TS8 + TS9 + TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
  CooperativeClassroomEnvironment =~ CCE1 + CCE2 + CCE3 + CCE4 + CCE5 + CCE6 + CCE7 + CCE8 + CCE9 + CCE10 + CCE11 + CCE12 + CCE13 + CCE14 + CCE15 + CCE16 + CCE17 + CCE18 + CCE19 + CCE20
'
fitcfa.global <- bcfa(modelcfa.global, data = df, std.lv = TRUE,
                      n.chains = n_chains, burnin=burn_in, 
                      sample=sample_estimate, target = "stan")
summary(fitcfa.global, standardized = TRUE, rsquare = TRUE)
fitMeasures(fitcfa.global)

semPaths(fitcfa.global,
         what = "std",      
         layout = "tree", 
         edge.label.cex = 1.0,
         sizeMan = 6,       
         sizeLat = 8,       
         nCharNodes = 6,    
         residuals = TRUE,        
         intercepts = FALSE,    
         optimizeLatRes = TRUE,  
         edge.color = "black",
         color = list(lat = "darkgreen", man = "white"),
         mar = c(6, 6, 6, 6) 
)
}
```



### 3 - SEM

Vamos utilizar mais cadeias mas menos samples para correr mais rápido. Este número de samples já permite convergir. :)

```{r}
# individual params
n_chains <- 3 # 5
burn_in <- 500
sample_estimate <- 1500
```


#### Estimação com construtos dos autores (dataset original)

Estes itens já foram vistos que serão a média correspondente aos itens escolhidos para os construtos.

```{r}
# ler csv 
df_FAauth <- read.csv("../data/4_conjuntos(dev)/construtos_autores.csv")
df_FAauth
```


```{r SEM com construtos autores}
if(correr_SEM){
  tic()
  model.sem_FAauthors <- '
    # regressions
    Motivation ~ Resilience + KnowledgeArticulation + TeamStrain + CoopClass
    SelfEfficacy ~ Resilience + KnowledgeArticulation + TeamStrain + CoopClass
    ethics ~ Motivation + SelfEfficacy
  '
  
  fit.sem_FAauthors <- bcfa(model.sem_FAauthors, data=df_FAauth, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan")
  toc()
}
```

```{r}
if(correr_SEM){
  summary(fit.sem_FAauthors, standardized=TRUE, rsquare=TRUE)
}
```

```{r}
if(correr_SEM){
  semPaths(fit.sem_FAauthors,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 10,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "lightblue"),
           mar = c(6, 6, 6, 6) 
  )
}
```

#### Construtos criados por nós

```{r}
df_FAour <- read.csv("../data/4_conjuntos(dev)/df_OUR_results.csv")
df_FAour
```


##### Média variáveis

Vai ser igual à análise de cima, mas com as médias das variáveis desta vez criada por nós.

```{r SEM com nossas médias}
if(correr_SEM){
  tic()
  model.sem_meanOUR <- '
    # regressions
    mean_factor_Motivation ~ mean_factor_Resilience + mean_factor_KnowledgeArticulation + mean_factor_TeamStrain + mean_factor_CooperativeClassroomEnvironment
    mean_factor_SelfEfficacy ~ mean_factor_Resilience + mean_factor_KnowledgeArticulation + mean_factor_TeamStrain + mean_factor_CooperativeClassroomEnvironment
    mean_factor_Ethics ~ mean_factor_Motivation + mean_factor_SelfEfficacy
  '
  
  fit.sem_meanOUR <- bcfa(model.sem_meanOUR, data=df_FAour, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan")
  toc()
}
```

```{r}
if(correr_SEM){
  summary(fit.sem_meanOUR, standardized=TRUE, rsquare=TRUE)
}
```

```{r}
if(correr_SEM){
  semPaths(fit.sem_meanOUR,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 10,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "lightblue"),
           mar = c(6, 6, 6, 6) 
  )
}
```

Conseguimos replicar na perfeição os valores do artigo.

##### CFA

```{r SEM com nosso CFA}
if(correr_SEM){
  tic()
  model.sem_CFAOUR <- '
    # regressions
    score_factor_Motivation ~ score_factor_Resilience + score_factor_KnowledgeArticulation + score_factor_TeamStrain + score_factor_CooperativeClassroomEnvironment
    score_factor_SelfEfficacy ~ score_factor_Resilience + score_factor_KnowledgeArticulation + score_factor_TeamStrain + score_factor_CooperativeClassroomEnvironment
    score_factor_Ethics ~ score_factor_Motivation + score_factor_SelfEfficacy
  '
  
  fit.sem_CFAOUR <- bcfa(model.sem_CFAOUR, data=df_FAour, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan")
  toc()
}
```

```{r}
if(correr_SEM){
  summary(fit.sem_CFAOUR, standardized=TRUE, rsquare=TRUE)
}
```

```{r}
if(correr_SEM){
  semPaths(fit.sem_CFAOUR,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 10,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "lightblue"),
           mar = c(6, 6, 6, 6) 
  )
}
```

#### Estimação seguida com FA criadas no próprio modelo

Agora faremos uma abordagem full SEM que consiste em fazer a modelação de todos os construtos e depois fazer a modelação SEM. Vamos replicar na exatidão o que é proposto no artigo mas tudo seguido e não CFA seguido de SEM.


```{r full SEM com sugestao autores}
if(correr_SEM){
  tic()
  model.sem <- '
    # measurement model
    StudentEthics =~ ET12 + ET13
    Motivation =~ Mot5 + Mot8 + Mot11
    SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
    Resilience =~ R2 + R5 + R6
    KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
    TeamStrain =~ TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
    CooperativeClassroomEnvironment =~ CCE1 + CCE3 + CCE4 + CCE5 + CCE8 + CCE9 + CCE10 + CCE11
    
    # regressions
    Motivation ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    SelfEfficacy ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    StudentEthics ~ Motivation + SelfEfficacy
    
  '
  
  fit.sem <- bcfa(model.sem, data=df, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan")
  toc()
}
```


```{r}
if(correr_SEM){
  summary(fit.sem, standardized=TRUE, rsquare=TRUE)
}
```

```{r}
if(correr_SEM){
  inspect(fit.sem, what = "std")$lambda
}
```


```{r, fig.width=12, fig.height=10}
if(correr_SEM){
  semPaths(fit.sem,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 0.4,
           sizeMan = 3,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "white"),
           mar = c(6, 6, 6, 6) 
  )
}
```

```{r, echo=TRUE, results='hide'}
if (correr_SEM) {
  mcs_SEM <- blavInspect(fit.sem, "mcmc")
  mcs_SEM <- as.matrix(mcs_SEM)

  analisar_coluna <- function(col_data, nome_coluna) {
    col_data <- as.numeric(col_data)
    col_data <- col_data[!is.na(col_data)]

    if (length(unique(col_data)) < 2) {
      return(NULL)
    }

    p <- quantile(col_data, probs = c(0.05, 0.25, 0.5, 0.75, 0.95), na.rm = TRUE)
    media <- mean(col_data)
    sd_val <- sd(col_data)
    
    fit_norm <- fitdist(col_data, "norm")
    fit_lognorm <- tryCatch(fitdist(col_data, "lnorm"), error = function(e) NULL)
    fit_gamma <- tryCatch(fitdist(col_data, "gamma"), error = function(e) NULL)
    fit_exp <- tryCatch(fitdist(col_data, "exp"), error = function(e) NULL)

    fits <- list(norm = fit_norm, lnorm = fit_lognorm, gamma = fit_gamma, exp = fit_exp)
    aic_vals <- sapply(fits, function(f) if (!is.null(f)) f$aic else Inf)
    best_dist <- names(which.min(aic_vals))

    data.frame(
      variavel = nome_coluna,
      p5 = p[1],
      p25 = p[2],
      p50 = p[3],
      p75 = p[4],
      p95 = p[5],
      media = media,
      sd = sd_val,
      melhor_distribuicao = best_dist,
      stringsAsFactors = FALSE
    )
  }

  resultados <- lapply(seq_len(ncol(mcs_SEM)), function(i) {
    analisar_coluna(mcs_SEM[, i], colnames(mcs_SEM)[i])
  })

  resumo_mcs <- do.call(rbind, Filter(Negate(is.null), resultados))
}
```


```{r}
if (correr_SEM) {
  dim(mcs_SEM) 
  # colnames(mcs_SEM)
  
  # mean(mcs_SEM[,1])
  # sd(mcs_SEM[,1])
  
  hist(mcs_SEM[,1]) # dist normal
  hist(mcs_SEM[,4]) # tem dist gamma?
  
  sum(mcs_SEM[,1] > .74)/nrow(mcs_SEM) # [1] 0.9995556
}
```


```{r}
if (correr_SEM) {
  resumo_mcs
}
```


```{r}
if (correr_SEM) {
  ML_SEM_bs <- blavFitIndices(fit.sem)
  summary(ML_SEM_bs, prob=.95,central.tendency = c("mean","median"))
}
```

```{r}
if (correr_SEM) {
  distML_SEM <- data.frame(ML_SEM_bs@indices)  
  sum(distML_SEM$BGammaHat > .88)/nrow(distML_SEM) # maior que .88
  hist(distML_SEM$BGammaHat)
}
```


```{r}
if (correr_SEM) {
  mcmc_pairs(distML_SEM, pars = c("BRMSEA","BGammaHat","adjBGammaHat"), diag_fun = 
  "hist")
}
```


#### Tentativa de melhoria com o SEM seguido

```{r full SEM com nossa sugestão}
if(correr_SEM){
  tic()
  model.sem_fullpurpose <- '
    # measurement model
    StudentEthics =~ ET12 + ET13
    Motivation =~ Mot5 + Mot8 + Mot11
    SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
    Resilience =~ R5 + R6
    KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
    TeamStrain =~ TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
    CooperativeClassroomEnvironment =~ CCE1 + CCE5 + CCE10 + CCE11 + CCE16 + CCE17 + CCE18 + CCE19
    
    # regressions
    Motivation ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    SelfEfficacy ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    StudentEthics ~ Motivation + SelfEfficacy
    
  '
  
  fit.sem_fullpurpose <- bcfa(model.sem_fullpurpose, data=df, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan")
  toc()
}
```


```{r}
if(correr_SEM){
  summary(fit.sem_fullpurpose, standardized=TRUE, rsquare=TRUE)
}
```

```{r}
if(correr_SEM){
  inspect(fit.sem_fullpurpose, what = "std")$lambda
}
```


```{r, fig.width=12, fig.height=10}
if(correr_SEM){
  semPaths(fit.sem_fullpurpose,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 0.4,
           sizeMan = 3,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "white"),
           mar = c(6, 6, 6, 6) 
  )
}
```

#### Comparação entre os dois SEM

```{r compfullSEM}
if(correr_SEM){
  blavCompare(fit.sem_FAauthors, fit.sem_meanOUR)
  # blavCompare(fit.sem, fit.sem_FAauthors) # não comparável
  # blavCompare(fit.sem_fullpurpose, fit.sem_FAauthors) # não comparável
  blavCompare(fit.sem, fit.sem_fullpurpose)
}
```

### 4- SEM com priors

#### Priors para lambda, beta e ET12 e ET13

Estudo de algumas priors baseado nos valores de loadings obtidos e os do paper. Veremos algumas distribuições conhecidas e tentar adaptar o valor do lambda para uma normal porque a função `dpriors` tem limitações em quais priors pode replicar.

```{r graficos priors}
curve(dgamma(x, 25, 50), from=0, to=1.2, main="(X) Prior para Lambda (loadings)", col = "green", ylab="Densidade")
abline(v=c(0.3, 1), col="red", lty=2)

curve(dlnorm(x, meanlog = -0.7, sdlog = 0.3),
      from = 0, to = 1.5, 
      col = "green", lwd = 2,
      ylab = "Densidade", xlab = "Valor do Loading",
      main = "(X) Distribuicao Lognormal(-0.7, 0.3) para Lambda (loadings)")
abline(v = c(0.3, 0.8), col = "red", lty = 2)

curve(dnorm(x, 0.5, 0.1), from=0, to=1.2, main="Prior para Lambda (loadings)", col = "green", ylab="Densidade")
abline(v=c(0.3, 1), col="red", lty=2)

curve(c(dnorm(x, 0.85, 0.05)), from=-1, to=1, col = "green", main="Prior para Lambda (loadings - ET12)", ylab="Densidade")
abline(v=c(0.75, 1.0), col="red", lty=2)

curve(c(dnorm(x, 0.7, 0.05)), from=-1, to=1, col = "green", main="Prior para Lambda (loadings - ET13)", ylab="Densidade")
abline(v=c(0.6, 0.83), col="red", lty=2)



curve(dnorm(x, 0, 0.25), from=-1, to=1,col = "blue", main="Prior para Beta (regressao)", ylab="Densidade")
abline(v=c(-0.5, 0.4), col="red", lty=2)
```

A distribuição gamma(1,.5) parece adequada para as variâncias porque tem valores acima de 0 e não tem cauda longa. Tem uma grande distribuição de pontos próximos de 0, o que parece interessante.

```{r}
plot(seq(0,10,.1), dgamma(seq(0,10,.1),5, 10), type="l", lty=1, lwd = 3, xlab="x value",
     ylab="Density", main="Prior Var: gamma distribution (5,10) & (1,0.5)", col = "darkgreen")
abline(v=.8, col="orange", lwd=2)
lines(seq(0,10,.1), dgamma(seq(0,10,.1),1,0.5), col = "darkblue", lwd = 3, lty = 2)
```



```{r}
# individual params
n_chains <- 3 # 3
burn_in <- 500 # 200
sample_estimate <- 1500 #1000
```


```{r modeloSEM com priors}
if(correr_SEM_cpriors){
  tic()
  dp <- dpriors(lambda = "normal(0.5, 0.1)", # semelhante "gamma(25, 50)"; nao conchigo utilizar gamma :(
                beta   = "normal(0, 0.25)" # talvez aumentar um pouco mais sd (cauda mais longa)
                #, theta  = "gamma(5, 10)" # variances
                ) 
  model.sem_priors <- '
    # measurement model
    StudentEthics =~ prior("normal(0.85, 0.05)")*ET12 + prior("normal(0.7, 0.05)")*ET13
    Motivation =~ Mot5 + Mot8 + Mot11
    SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
    Resilience =~ R2 + R5 + R6
    KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
    TeamStrain =~ TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
    CooperativeClassroomEnvironment =~ CCE1 + CCE3 + CCE4 + CCE5 + CCE8 + CCE9 + CCE10 + CCE11
    
    # regressions
    Motivation ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    SelfEfficacy ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    StudentEthics ~ Motivation + SelfEfficacy
    
  '
  
  fit.sem_priors <- bcfa(model.sem_priors, data=df, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan", dp = dp)
  toc()
}
```

```{r summarySEM com priors}
if(correr_SEM_cpriors){
  summary(fit.sem_priors, standardized=TRUE, rsquare=TRUE)
}
```


```{r SEMmodelgraphic com priors}
if(correr_SEM_cpriors){
  semPaths(fit.sem_priors,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 10,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "lightblue"),
           mar = c(6, 6, 6, 6) 
  )
}
```

```{r dist SEM com priors}
if(correr_SEM_cpriors){
  ML_SEMpriors_bs <- blavFitIndices(fit.sem_priors)
  summary(ML_SEMpriors_bs, prob=.95,central.tendency = c("mean","median"))
  distML_SEMpriors <- data.frame(ML_SEMpriors_bs@indices)
  mcmc_pairs(distML_SEMpriors, pars = c("BRMSEA","BGammaHat","adjBGammaHat"), diag_fun = 
    "hist")
}
```



```{r comparacaoSEM}
if(correr_SEM_cpriors){
  blavCompare(fit.sem_priors, fit.sem)
  (fits_SEModels <- cbind(fitMeasures(fit.sem_priors), fitMeasures(fit.sem)))
}
```

#### Priors com regressão 0

```{r modeloSEM com priors reg0}
if(correr_SEM_cpriors){
  tic() 
  model.sem_priors_reg0 <- '
    # measurement model
    StudentEthics =~ ET12 + ET13
    Motivation =~ Mot5 + Mot8 + Mot11
    SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
    Resilience =~ R2 + R5 + R6
    KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
    TeamStrain =~ TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
    CooperativeClassroomEnvironment =~ CCE1 + CCE3 + CCE4 + CCE5 + CCE8 + CCE9 + CCE10 + CCE11
    
    # regressions
    Motivation ~ Resilience + KnowledgeArticulation + TeamStrain + prior("normal(0, 0.001)")*CooperativeClassroomEnvironment
    SelfEfficacy ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    StudentEthics ~ Motivation + SelfEfficacy
    
  '
  
  fit.sem_priors_reg0 <- bcfa(model.sem_priors_reg0, data=df, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan")
  toc()
}
```

```{r summarySEM com priors reg0}
if(correr_SEM_cpriors){
  summary(fit.sem_priors_reg0, standardized=TRUE, rsquare=TRUE)
}
```


```{r SEMmodelgraphic com priors reg0}
if(correr_SEM_cpriors){
  semPaths(fit.sem_priors_reg0,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 10,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "lightblue"),
           mar = c(6, 6, 6, 6) 
  )
}
```


```{r dist SEM com priors reg0}
if(correr_SEM_cpriors){
  ML_SEMpriors0_bs <- blavFitIndices(fit.sem_priors_reg0)
  summary(ML_SEMpriors0_bs, prob=.95,central.tendency = c("mean","median"))
  distML_SEMpriors0 <- data.frame(ML_SEMpriors0_bs@indices)
  mcmc_pairs(distML_SEMpriors0, pars = c("BRMSEA","BGammaHat","adjBGammaHat"), diag_fun = 
    "hist")
}
```


```{r comparacaoSEM reg0}
if(correr_SEM_cpriors){
  blavCompare(fit.sem_priors, fit.sem_priors_reg0)
  (fits_SEModels <- cbind(fitMeasures(fit.sem_priors), fitMeasures(fit.sem_priors_reg0)))
}
```

#### Priors com todas priors

```{r modeloSEM com priors all}
if(correr_SEM_cpriors){
  tic()
  dp <- dpriors(lambda = "normal(0.5, 0.1)", # semelhante "gamma(25, 50)"; nao conchigo utilizar gamma :(
                beta   = "normal(0, 0.25)" # talvez aumentar um pouco mais sd (cauda mais longa)
                #, theta  = "gamma(5, 10)" # variances
                ) 
  model.sem_priors_all <- '
    # measurement model
    StudentEthics =~ prior("normal(0.85, 0.05)")*ET12 + prior("normal(0.7, 0.05)")*ET13
    Motivation =~ Mot5 + Mot8 + Mot11
    SelfEfficacy =~ SE1 + SE2 + SE3 + SE4 + SE5 + SE6
    Resilience =~ R2 + R5 + R6
    KnowledgeArticulation =~ KA1 + KA2 + KA3 + KA4 + KA5
    TeamStrain =~ TS10 + TS11 + TS12 + TS13 + TS14 + TS15 + TS16 + TS17
    CooperativeClassroomEnvironment =~ CCE1 + CCE3 + CCE4 + CCE5 + CCE8 + CCE9 + CCE10 + CCE11
    
    # regressions
    Motivation ~ Resilience + KnowledgeArticulation + TeamStrain + prior("normal(0, 0.0001)")*CooperativeClassroomEnvironment
    SelfEfficacy ~ Resilience + KnowledgeArticulation + TeamStrain + CooperativeClassroomEnvironment
    StudentEthics ~ Motivation + SelfEfficacy
    
  '
  
  fit.sem_priors_all <- bcfa(model.sem_priors_all, data=df, std.lv=TRUE, n.chains = n_chains,
                   burnin=burn_in, sample=sample_estimate, target = "stan", dp = dp)
  toc()
}
```

```{r summarySEM com priors all}
if(correr_SEM_cpriors){
  summary(fit.sem_priors_all, standardized=TRUE, rsquare=TRUE)
}
```


```{r SEMmodelgraphic com priors all}
if(correr_SEM_cpriors){
  semPaths(fit.sem_priors_all,
           what = "std",      
           layout = "tree", 
           edge.label.cex = 1.0,
           sizeMan = 10,       
           sizeLat = 8,       
           nCharNodes = 6,    
           residuals = TRUE,        
           intercepts = FALSE,    
           optimizeLatRes = TRUE,  
           edge.color = "black",
           color = list(lat = "darkgreen", man = "lightblue"),
           mar = c(6, 6, 6, 6) 
  )
}
```

```{r dist SEM com priors all}
if(correr_SEM_cpriors){
  ML_SEMpriorsall_bs <- blavFitIndices(fit.sem_priors_all)
  summary(ML_SEMpriorsall_bs, prob=.95,central.tendency = c("mean","median"))
  distML_SEMpriorsall <- data.frame(ML_SEMpriorsall_bs@indices)
  mcmc_pairs(distML_SEMpriorsall, pars = c("BRMSEA","BGammaHat","adjBGammaHat"), diag_fun = 
    "hist")
}
```



```{r comparacaoSEM all}
if(correr_SEM_cpriors){
  blavCompare(fit.sem_priors, fit.sem_priors_reg0)
  blavCompare(fit.sem_priors, fit.sem_priors_all)
  (fits_SEModels <- cbind(fitMeasures(fit.sem), fitMeasures(fit.sem_priors), fitMeasures(fit.sem_priors_reg0), fitMeasures(fit.sem_priors_all)))
}
```



